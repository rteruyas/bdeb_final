name: Register Best Model and Upload to S3

on:
  # Run manually from the Actions tab
  workflow_dispatch:
  
  # Run on schedule (once a day at midnight UTC)
  # schedule:
  #   - cron: '0 0 * * *'

jobs:
  find-register-and-upload-model:
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mlflow pandas boto3
        
    - name: Create model registration script
      run: |
        cat > register_and_upload_model.py << 'EOL'
        import os
        import mlflow
        from mlflow.tracking import MlflowClient
        import boto3
        from pathlib import Path
        import tempfile
        import shutil

        def register_and_upload_model():
            """
            Search for all runs ending with 'final_evaluation' across all experiments,
            find the best performing model based on accuracy, register it to the MLflow Model Registry,
            download the model.pkl file, and upload it to an S3 bucket.
            """
            # Set MLflow tracking URI from environment variable
            tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
            if tracking_uri:
                mlflow.set_tracking_uri(tracking_uri)
                print(f"Using MLflow tracking URI: {tracking_uri}")
            else:
                print("MLFLOW_TRACKING_URI not set. Using default tracking URI.")
            
            # Set any required authentication
            if "MLFLOW_TRACKING_USERNAME" in os.environ and "MLFLOW_TRACKING_PASSWORD" in os.environ:
                os.environ["MLFLOW_TRACKING_TOKEN"] = f"{os.environ['MLFLOW_TRACKING_USERNAME']}:{os.environ['MLFLOW_TRACKING_PASSWORD']}"
                print("Using authentication from environment variables")
            
            print("Searching for experiments...")
            # Get all experiments
            experiments = mlflow.search_experiments()
            print(f"Found {len(experiments)} experiments")
            
            # Track the best model
            best_metric_value = float('-inf')
            best_run_id = None
            best_model_name = None
            
            # The metric to compare models
            target_metric = "accuracy"
            
            print(f"Searching for final evaluation runs and comparing by {target_metric}...")
            
            for experiment in experiments:
                experiment_id = experiment.experiment_id
                experiment_name = experiment.name
                
                print(f"Checking experiment: {experiment_name}")
                
                # Search for runs with names ending in 'final_evaluation'
                try:
                    runs = mlflow.search_runs(
                        experiment_ids=[experiment_id],
                        filter_string="attributes.run_name LIKE '%final_evaluation'"
                    )
                    print(f"  Available columns: {list(runs.columns)}")
                except Exception as e:
                    print(f"  Error searching runs: {e}")
                    continue
                
                if len(runs) == 0:
                    print(f"  No final evaluation runs found in {experiment_name}")
                    continue
                    
                print(f"  Found {len(runs)} final evaluation runs")
                
                # Process each run to find the best model
                for _, run in runs.iterrows():
                    run_id = run['run_id']
                    run_name = run['tags.mlflow.runName'] if 'tags.mlflow.runName' in run else run_id
                    
                    # Check if the target metric exists in this run
                    metric_column = f"metrics.{target_metric}"
                    if metric_column in run:
                        metric_value = run[metric_column]
                        print(f"  Run: {run_name}, {target_metric}: {metric_value}")
                        
                        # Compare with the best metric value (assuming higher is better)
                        if metric_value > best_metric_value:
                            best_metric_value = metric_value
                            best_run_id = run_id
                            best_model_name = run_name
                            print(f"  New best model found: {run_name} with {target_metric}: {metric_value}")
            
            # Register the best model and upload to S3
            if best_run_id:
                print(f"\nBest model found:")
                print(f"  Model: {best_model_name}")
                print(f"  {target_metric}: {best_metric_value}")
                print(f"  Run ID: {best_run_id}")
                
                # Step 1: Register the model in MLflow Registry
                try:
                    print(f"\nRegistering model to MLflow Model Registry...")
                    client = MlflowClient()
                    
                    # Define a model name
                    model_name = os.environ.get("MODEL_NAME", "best_model")
                    
                    # Use the standard model path
                    model_uri = f"runs:/{best_run_id}/model"
                    print(f"Using model URI: {model_uri}")
                    
                    # Check if model exists in registry
                    try:
                        existing_models = client.search_registered_models(filter_string=f"name='{model_name}'")
                        model_exists = len(existing_models) > 0
                        if not model_exists:
                            client.create_registered_model(model_name)
                            print(f"Created new registered model: {model_name}")
                    except Exception as e:
                        print(f"Note: Error checking if model exists (will try to create): {e}")
                        try:
                            client.create_registered_model(model_name)
                            print(f"Created new registered model: {model_name}")
                        except Exception as e2:
                            print(f"Note: Error creating model (it might already exist): {e2}")
                    
                    # Register the model
                    print(f"Registering model from run {best_run_id}...")
                    model_version = mlflow.register_model(
                        model_uri=model_uri,
                        name=model_name
                    )
                    version = model_version.version
                    print(f"Successfully registered model version: {version}")
                    
                    # Transition to Production
                    print(f"Setting model to Production stage...")
                    client.transition_model_version_stage(
                        name=model_name,
                        version=version,
                        stage="Production"
                    )
                    print(f"Model {model_name} version {version} is now in Production stage")
                    
                    # Set description
                    client.update_model_version(
                        name=model_name,
                        version=version,
                        description=f"Best model with {target_metric}={best_metric_value:.4f} from run: {best_model_name}"
                    )
                    
                    print(f"\nSUCCESS: Registered model as Production in the MLflow Model Registry")
                    print(f"Model name: {model_name}")
                    print(f"Model version: {version}")
                    print(f"Model {target_metric}: {best_metric_value:.4f}")
                    print(f"Original run: {best_model_name}")
                
                except Exception as e:
                    print(f"Error registering model: {str(e)}")
                    print(f"Run ID attempted: {best_run_id}")
                    print(f"Model URI attempted: {model_uri}")
                    raise
                
                # Step 2: Download model.pkl file
                try:
                    # Create a temporary directory to download the model
                    with tempfile.TemporaryDirectory() as temp_dir:
                        temp_path = Path(temp_dir)
                        
                        print(f"\nDownloading model.pkl file...")
                        
                        # First try to find where the model.pkl file is located
                        try:
                            print(f"Listing artifacts for run {best_run_id}")
                            artifacts = mlflow.artifacts.list_artifacts(best_run_id)
                            print(f"Found {len(artifacts)} artifacts at root level")
                            for artifact in artifacts:
                                print(f"  - {artifact.path} ({'directory' if artifact.is_dir else 'file'})")
                            
                            # First look for any .pkl files in the root
                            pkl_files = [a for a in artifacts if a.path.endswith('.pkl')]
                            if pkl_files:
                                pkl_path = pkl_files[0].path
                                print(f"Found PKL file at root level: {pkl_path}")
                            else:
                                # Then check common model directories
                                model_dirs = [a for a in artifacts if a.is_dir and (a.path == 'model' or 'model' in a.path)]
                                if model_dirs:
                                    # Check each potential model directory
                                    for model_dir in model_dirs:
                                        print(f"Checking directory: {model_dir.path}")
                                        try:
                                            dir_contents = mlflow.artifacts.list_artifacts(best_run_id, model_dir.path)
                                            for item in dir_contents:
                                                print(f"  - {item.path} ({'directory' if item.is_dir else 'file'})")
                                                
                                                # Check if this is a PKL file
                                                if item.path.endswith('.pkl'):
                                                    pkl_path = item.path
                                                    print(f"Found PKL file: {pkl_path}")
                                                    break
                                                    
                                                # Look in data subdirectory if present
                                                if item.is_dir and 'data' in item.path:
                                                    try:
                                                        data_contents = mlflow.artifacts.list_artifacts(best_run_id, item.path)
                                                        for data_item in data_contents:
                                                            print(f"    - {data_item.path} ({'directory' if data_item.is_dir else 'file'})")
                                                            if data_item.path.endswith('.pkl'):
                                                                pkl_path = data_item.path
                                                                print(f"Found PKL file in data dir: {pkl_path}")
                                                                break
                                                    except Exception as e:
                                                        print(f"Error listing data directory {item.path}: {e}")
                                        except Exception as e:
                                            print(f"Error listing directory {model_dir.path}: {e}")
                                            
                                        # If we found a PKL file, break out of the directory loop
                                        if 'pkl_path' in locals() and pkl_path:
                                            break
                                
                                # If still nothing found, do an exhaustive search of all directories
                                if 'pkl_path' not in locals() or not pkl_path:
                                    print("No PKL file found in common locations. Doing exhaustive search...")
                                    # Recursively check all directories
                                    def search_dir_for_pkl(run_id, dir_path=""):
                                        try:
                                            contents = mlflow.artifacts.list_artifacts(run_id, dir_path)
                                            for item in contents:
                                                if item.path.endswith('.pkl'):
                                                    return item.path
                                                if item.is_dir:
                                                    result = search_dir_for_pkl(run_id, item.path)
                                                    if result:
                                                        return result
                                            return None
                                        except Exception as e:
                                            print(f"Error searching directory {dir_path}: {e}")
                                            return None
                                    
                                    pkl_path = search_dir_for_pkl(best_run_id)
                                    if pkl_path:
                                        print(f"Found PKL file in exhaustive search: {pkl_path}")
                            
                                # If we couldn't find a PKL file, try to export the MLflow model
                                if 'pkl_path' not in locals() or not pkl_path:
                                    print("No PKL file found in artifacts. Attempting to download MLflow model folder...")
                                    try:
                                        # Download the entire model directory
                                        model_download_path = mlflow.artifacts.download_artifacts(
                                            artifact_uri=f"runs:/{best_run_id}/model",
                                            dst_path=str(temp_path)
                                        )
                                        model_dir = Path(model_download_path)
                                        
                                        if model_dir.exists():
                                            print(f"Successfully downloaded model directory to: {model_dir}")
                                            
                                            # Try to find any PKL files in the downloaded directory
                                            pkl_files = list(model_dir.glob('**/*.pkl'))
                                            if pkl_files:
                                                output_file = temp_path / "model.pkl"
                                                shutil.copy(pkl_files[0], output_file)
                                                print(f"Found and copied PKL file to model.pkl: {pkl_files[0]}")
                                            else:
                                                # If no PKL file found, use MLflow to save the model
                                                print("No PKL files found in model directory. Using MLflow to load and save model...")
                                                try:
                                                    # Try to load the MLflow model and save it in pickle format
                                                    output_file = temp_path / "model.pkl"
                                                    model = mlflow.pyfunc.load_model(f"runs:/{best_run_id}/model")
                                                    mlflow.sklearn.save_model(model, path=str(temp_path / "sklearn_model"))
                                                    
                                                    # Find the saved model file
                                                    new_pkl_files = list((temp_path / "sklearn_model").glob('**/*.pkl'))
                                                    if new_pkl_files:
                                                        shutil.copy(new_pkl_files[0], output_file)
                                                        print(f"Successfully saved model as pickle: {output_file}")
                                                    else:
                                                        print("Failed to find PKL file after saving model")
                                                        raise Exception("Could not create model.pkl file")
                                                except Exception as e:
                                                    print(f"Error saving model as pickle: {e}")
                                                    raise Exception("Could not create model.pkl file")
                                        else:
                                            raise Exception("Failed to download model directory")
                                    except Exception as e:
                                        print(f"Error downloading model directory: {e}")
                                        raise Exception("Could not find or create model.pkl file")
                            
                            # If we've found or created a PKL file, upload it to S3
                                    # Download the pkl file
                                    artifact_uri = f"runs:/{best_run_id}/{pkl_path}"
                                    output_file = temp_path / "model.pkl"
                                    
                                    try:
                                        # Download the specific file
                                        download_path = mlflow.artifacts.download_artifacts(
                                            artifact_uri=artifact_uri,
                                            dst_path=str(temp_path)
                                        )
                                        downloaded_file = Path(download_path)
                                        
                                        # Make sure the file is named model.pkl
                                        if downloaded_file.name != "model.pkl":
                                            shutil.copy(downloaded_file, output_file)
                                            print(f"Renamed to model.pkl: {str(output_file)}")
                                        else:
                                            output_file = downloaded_file
                                            
                                        print(f"Successfully downloaded model file to: {str(output_file)}")
                                        
                                        # Step 3: Upload to S3
                                        s3_bucket = os.environ.get("S3_BUCKET_NAME")
                                        s3_key = os.environ.get("S3_KEY_PREFIX", "models") + "/model.pkl"
                                        
                                        if s3_bucket:
                                            print(f"\nUploading model.pkl to S3...")
                                            s3_client = boto3.client(
                                                's3',
                                                aws_access_key_id=os.environ.get("AWS_ACCESS_KEY_ID"),
                                                aws_secret_access_key=os.environ.get("AWS_SECRET_ACCESS_KEY"),
                                                region_name=os.environ.get("AWS_REGION", "us-east-1")
                                            )
                                            
                                            s3_client.upload_file(
                                                str(output_file),
                                                s3_bucket,
                                                s3_key
                                            )
                                            
                                            print(f"SUCCESS: Uploaded model.pkl to S3")
                                            print(f"S3 Location: s3://{s3_bucket}/{s3_key}")
                                        else:
                                            print("S3_BUCKET_NAME not set. Skipping S3 upload.")
                                    except Exception as e:
                                        print(f"Error downloading or uploading model file: {e}")
                                else:
                                    print("Could not find a .pkl file in the model artifacts")
                            else:
                                print("Could not find model directory or model.pkl in artifacts")
                                
                        except Exception as e:
                            print(f"Error listing artifacts: {e}")
                        
                except Exception as e:
                    print(f"Error downloading model: {str(e)}")
            else:
                print(f"\nNo models found with metric '{target_metric}' across all final evaluation runs.")

        if __name__ == "__main__":
            try:
                register_and_upload_model()
            except Exception as e:
                print(f"Error: {e}")
                exit(1)
        EOL
      
    - name: Run model registration and S3 upload
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
        MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}
        MODEL_NAME: "best_model"
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        S3_KEY_PREFIX: "mlflow-models"
      run: |
        python register_and_upload_model.py